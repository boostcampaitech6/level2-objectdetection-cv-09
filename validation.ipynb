{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, cv2, tqdm\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyMapper(dataset_dict):\n",
    "    \n",
    "    dataset_dict = copy.deepcopy(dataset_dict)\n",
    "    image = utils.read_image(dataset_dict['file_name'], format='BGR')\n",
    "    \n",
    "    dataset_dict['image'] = image\n",
    "    \n",
    "    return dataset_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4871 [00:00<?, ?it/s]/data/ephemeral/home/level2-objectdetection-cv-09/detectron2/structures/image_list.py:99: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  max_size = (max_size + (stride - 1)) // stride * stride\n",
      "/opt/conda/lib/python3.10/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "try:\n",
    "    register_coco_instances('coco_trash_test', {}, '../dataset/test.json', '../dataset/')\n",
    "except AssertionError:\n",
    "    pass\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file('COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml'))\n",
    "TrashMeta = MetadataCatalog.get(\"coco_trash_test\")\n",
    "# config 수정하기\n",
    "cfg.DATASETS.TEST = ('coco_trash_test',)\n",
    "cfg.DATALOADER.NUM_WOREKRS = 2\n",
    "cfg.OUTPUT_DIR = './output'\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, 'model_final.pth')\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 10\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "test_loader = build_detection_test_loader(cfg, 'coco_trash_test', MyMapper)\n",
    "\n",
    "BreakCounter = 100\n",
    "for data in tqdm(test_loader):\n",
    "    \n",
    "    data = data[0]\n",
    "    im = cv2.imread(data['file_name'])\n",
    "    outputs = predictor(data['image'])['instances']\n",
    "    output = predictor(im)\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                    metadata = TrashMeta,\n",
    "                    scale=0.5,\n",
    "                    instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
    "                    )\n",
    "    out = v.draw_instance_predictions(output[\"instances\"].to(\"cpu\"))\n",
    "    os.makedirs('output/validation', exist_ok=True)\n",
    "    #fdir=data['file_name'].replace('../dataset/test','output/validation')\n",
    "    #cv2.imwrite(fdir, out.get_image()[:, :, ::-1])\n",
    "    ImageId = data['file_name'].replace('../dataset/test','')\n",
    "    cv2.imshow(ImageId, out.get_image()[:, :, ::-1])\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    \n",
    "    if BreakCounter == 0:\n",
    "        break\n",
    "    else:\n",
    "        BreakCounter=BreakCounter-1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
